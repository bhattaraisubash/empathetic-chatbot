{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc0b3a85-6816-46bd-bc4e-a4b84fa89ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeac9e88-089d-4451-8b9a-8651b2a29627",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'Best book?', 'How old?', 'Your job?', 'Best food?', 'Pets?',\n",
    "    'Coffee or tea?', 'Best movie?', 'Hobbies?', 'Favorite color?', 'Morning person?',\n",
    "    'Travel dream?', 'Workout?', 'Dream job?', 'Your hero?', 'Best book?',\n",
    "    'Pets?', 'Morning person?', 'Workout?', 'Coffee or tea?', 'Dream job?',\n",
    "    'Best food?', 'Travel dream?', 'Your job?', 'Best movie?', 'Favorite color?',\n",
    "    'How old?', 'Hobbies?', 'Your hero?', 'Pets?', 'Coffee or tea?',\n",
    "    'Morning person?', 'Best movie?', 'Workout?', 'Dream job?', 'Your job?',\n",
    "    'Favorite color?', 'Travel dream?', 'Best food?', 'How old?', 'Hobbies?',\n",
    "    'Your hero?', 'Best book?', 'Pets?', 'Coffee or tea?', 'Morning person?',\n",
    "    'Best movie?', 'Workout?', 'Dream job?', 'Your job?', 'Favorite color?'\n",
    "]\n",
    "\n",
    "answers = [\n",
    "    'Sushi is the best food ever.', \"The best movie is 'Inception'.\", 'My hero is Marie Curie.', 'I have two dogs.', \"My favorite book is '1984' by George Orwell.\",\n",
    "    'Definitely coffee.', 'No, I\\'m definitely not a morning person.', 'Yes, I workout 5 days a week.', 'I dream of being an astronaut.', 'I\\'m 29 years old.',\n",
    "    'I love the color blue.', 'I enjoy hiking and painting.', 'I dream of traveling to Japan.', 'I\\'m a software engineer.', 'Not much, you?',\n",
    "    'My favorite book is \\'1984\\' by George Orwell.', 'I have two dogs.', 'Definitely coffee.', 'Yes, I workout 5 days a week.', 'I dream of being an astronaut.',\n",
    "    'Sushi is the best food ever.', 'I dream of traveling to Japan.', 'I\\'m a software engineer.', \"The best movie is 'Inception'.\", 'I love the color blue.',\n",
    "    'I\\'m 29 years old.', 'I enjoy hiking and painting.', 'My hero is Marie Curie.', 'Not much, you?', 'Definitely coffee.',\n",
    "    'No, I\\'m definitely not a morning person.', \"The best movie is 'Inception'.\", 'Yes, I workout 5 days a week.', 'I dream of being an astronaut.', 'I\\'m a software engineer.',\n",
    "    'I love the color blue.', 'I dream of traveling to Japan.', 'Sushi is the best food ever.', 'I\\'m 29 years old.', 'I enjoy hiking and painting.',\n",
    "    'My hero is Marie Curie.', 'Not much, you?', 'My favorite book is \\'1984\\' by George Orwell.', 'Definitely coffee.', 'No, I\\'m definitely not a morning person.',\n",
    "    \"The best movie is 'Inception'.\", 'Yes, I workout 5 days a week.', 'I dream of being an astronaut.', 'I\\'m a software engineer.', 'I love the color blue.'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0219cf57-7358-4d36-b6bb-7d75bf4afb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "#        max_len = 13         #\n",
    "###############################\n",
    "\n",
    "sorted_ques = []\n",
    "sorted_ans = []\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "#                             #\n",
    "###############################\n",
    "len(sorted_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a847539-c63e-4fa1-ab7c-f68c0470f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c68f6b0-ad2d-472e-97f9-1c7237a3ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ques = []\n",
    "clean_ans = []\n",
    "\n",
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "        \n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))\n",
    "\n",
    "\n",
    "\n",
    "## delete\n",
    "del(answers, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b31376f-b7ea-477e-a4ff-565aac7c1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "\n",
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "del(sorted_ans, sorted_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8bc90eb-f837-4f5f-a32e-a7cd0c72188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## trimming\n",
    "clean_ans=clean_ans[:30000]\n",
    "clean_ques=clean_ques[:30000]\n",
    "## delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d97ed92-0fc8-477d-8fc9-f843dde40c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  count occurences ###\n",
    "word2count = {}\n",
    "\n",
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3496349-19f8-49d9-8211-04334b8a7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  remove less frequent ###\n",
    "thresh = 0 #change it later\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66cf5e33-45fd-4732-88d6-bea826f50678",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
    "\n",
    "\n",
    "\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1\n",
    "    \n",
    "    \n",
    "\n",
    "#vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02f49795-b772-446d-bb17-121cbfdb1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inv answers dict ###\n",
    "inv_vocab = {w:v for v, w in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02b65920-706d-406c-bbcf-02529d183492",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "        \n",
    "    encoder_inp.append(lst)\n",
    "\n",
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])        \n",
    "    decoder_inp.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7401545-87dd-4b07-a96a-2fb926b41df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder_final_output = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:]) \n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0b75160-e639-4673-a89f-e15432435ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 13) (35, 13) (35, 13) 63 62 <PAD>\n"
     ]
    }
   ],
   "source": [
    "# decoder_final_output, decoder_final_input, encoder_final, vocab, inv_vocab\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "MAX_LEN = 13\n",
    "\n",
    "print(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3899077-1f45-427d-a68b-ca51894dae0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best': 0,\n",
       " 'book': 1,\n",
       " 'how': 2,\n",
       " 'old': 3,\n",
       " 'your': 4,\n",
       " 'job': 5,\n",
       " 'food': 6,\n",
       " 'pets': 7,\n",
       " 'movie': 8,\n",
       " 'hobbies': 9,\n",
       " 'workout': 10,\n",
       " 'dream': 11,\n",
       " 'hero': 12,\n",
       " 'sushi': 13,\n",
       " 'is': 14,\n",
       " 'the': 15,\n",
       " 'ever': 16,\n",
       " 'inception': 17,\n",
       " 'my': 18,\n",
       " 'marie': 19,\n",
       " 'curie': 20,\n",
       " 'i': 21,\n",
       " 'have': 22,\n",
       " 'two': 23,\n",
       " 'dogs': 24,\n",
       " 'favorite': 25,\n",
       " '1984': 26,\n",
       " 'by': 27,\n",
       " 'george': 28,\n",
       " 'orwell': 29,\n",
       " 'no': 30,\n",
       " 'am': 31,\n",
       " 'definitely': 32,\n",
       " 'not': 33,\n",
       " 'a': 34,\n",
       " 'morning': 35,\n",
       " 'person': 36,\n",
       " 'yes': 37,\n",
       " '5': 38,\n",
       " 'days': 39,\n",
       " 'week': 40,\n",
       " 'enjoy': 41,\n",
       " 'hiking': 42,\n",
       " 'and': 43,\n",
       " 'painting': 44,\n",
       " 'of': 45,\n",
       " 'traveling': 46,\n",
       " 'to': 47,\n",
       " 'japan': 48,\n",
       " 'software': 49,\n",
       " 'engineer': 50,\n",
       " 'much': 51,\n",
       " 'you': 52,\n",
       " 'coffee': 53,\n",
       " 'being': 54,\n",
       " 'an': 55,\n",
       " 'astronaut': 56,\n",
       " '29': 57,\n",
       " 'years': 58,\n",
       " '<PAD>': 0,\n",
       " '<EOS>': 60,\n",
       " '<OUT>': 61,\n",
       " '<SOS>': 62}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35b4ec95-bb6e-4624-be4f-5678b50ace89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: 'book',\n",
       " 2: 'how',\n",
       " 3: 'old',\n",
       " 4: 'your',\n",
       " 5: 'job',\n",
       " 6: 'food',\n",
       " 7: 'pets',\n",
       " 8: 'movie',\n",
       " 9: 'hobbies',\n",
       " 10: 'workout',\n",
       " 11: 'dream',\n",
       " 12: 'hero',\n",
       " 13: 'sushi',\n",
       " 14: 'is',\n",
       " 15: 'the',\n",
       " 16: 'ever',\n",
       " 17: 'inception',\n",
       " 18: 'my',\n",
       " 19: 'marie',\n",
       " 20: 'curie',\n",
       " 21: 'i',\n",
       " 22: 'have',\n",
       " 23: 'two',\n",
       " 24: 'dogs',\n",
       " 25: 'favorite',\n",
       " 26: '1984',\n",
       " 27: 'by',\n",
       " 28: 'george',\n",
       " 29: 'orwell',\n",
       " 30: 'no',\n",
       " 31: 'am',\n",
       " 32: 'definitely',\n",
       " 33: 'not',\n",
       " 34: 'a',\n",
       " 35: 'morning',\n",
       " 36: 'person',\n",
       " 37: 'yes',\n",
       " 38: '5',\n",
       " 39: 'days',\n",
       " 40: 'week',\n",
       " 41: 'enjoy',\n",
       " 42: 'hiking',\n",
       " 43: 'and',\n",
       " 44: 'painting',\n",
       " 45: 'of',\n",
       " 46: 'traveling',\n",
       " 47: 'to',\n",
       " 48: 'japan',\n",
       " 49: 'software',\n",
       " 50: 'engineer',\n",
       " 51: 'much',\n",
       " 52: 'you',\n",
       " 53: 'coffee',\n",
       " 54: 'being',\n",
       " 55: 'an',\n",
       " 56: 'astronaut',\n",
       " 57: '29',\n",
       " 58: 'years',\n",
       " 60: '<EOS>',\n",
       " 61: '<OUT>',\n",
       " 62: '<SOS>'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d88cae73-1f5b-4ba0-8788-3d020bbc7cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 13, 63)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "\n",
    "decoder_final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9437b388-f07f-4820-81fa-f0997ea9f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe Loded!\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('../dataset/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print(\"GloVe Loded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f141be6b-df89-40df-a762-473a4f6e9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "embedding_matrix = embedding_matrix_creater(50, word_index=vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6095be17-0d40-4beb-9a3e-2d3126b217cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83c53272-ae90-49c9-91a4-fe9ffb27b283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.15719986e-01,  6.03450000e-01, -3.10770005e-01,  2.84330010e-01,\n",
       "        5.46100020e-01, -3.92290018e-03, -9.46399987e-01, -3.02100003e-01,\n",
       "        7.11499974e-02,  8.23849976e-01, -1.69489995e-01,  4.10540015e-01,\n",
       "       -4.86220002e-01,  6.14830017e-01,  7.04680026e-01, -6.00319982e-01,\n",
       "        8.93819988e-01,  1.17810003e-01, -7.78310001e-01, -5.22059977e-01,\n",
       "       -1.00769997e-01,  3.83920014e-01,  2.78919995e-01,  3.72020006e-01,\n",
       "        4.93739992e-01, -1.14950001e+00, -1.15050006e+00, -7.20889986e-01,\n",
       "       -3.80900018e-02, -4.56990004e-01,  3.34249997e+00,  5.66600025e-01,\n",
       "        8.89440009e-04, -2.00299993e-01,  5.36620021e-01,  2.84779996e-01,\n",
       "       -8.38219970e-02,  9.75350022e-01, -3.59849989e-01, -1.08179998e+00,\n",
       "       -5.15550002e-02,  3.04529995e-01,  4.71549993e-03, -2.52139986e-01,\n",
       "       -3.51509988e-01,  2.61350006e-01,  1.99980006e-01, -5.60319982e-02,\n",
       "        7.49880001e-02,  7.60919988e-01])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4a44855-d41b-4c4b-96bc-7fa9a80e45d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 11:33:14.367221: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-27 11:33:14.367856: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention\n",
    "\n",
    "embed = Embedding(VOCAB_SIZE+1, \n",
    "                  50, \n",
    "                  \n",
    "                  input_length=13,\n",
    "                  trainable=True)\n",
    "\n",
    "embed.build((None,))\n",
    "embed.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b53103c3-aa4e-4fc7-bdfa-49128c01e76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 13, 50)       3200        ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  [(None, 13, 800),   1443200     ['embedding[2][0]']              \n",
      " )                               (None, 400),                                                     \n",
      "                                 (None, 400),                                                     \n",
      "                                 (None, 400),                                                     \n",
      "                                 (None, 400)]                                                     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 800)          0           ['bidirectional_1[0][1]',        \n",
      "                                                                  'bidirectional_1[0][3]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 800)          0           ['bidirectional_1[0][2]',        \n",
      "                                                                  'bidirectional_1[0][4]']        \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 13, 800),    2723200     ['embedding[3][0]',              \n",
      "                                 (None, 800),                     'concatenate_2[0][0]',          \n",
      "                                 (None, 800)]                     'concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, 13, 800),   1280800     ['bidirectional_1[0][0]',        \n",
      " r)                              (None, 13, 13))                  'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 13, 1600)     0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 13, 63)       100863      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,551,263\n",
      "Trainable params: 5,551,263\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building model\n",
    "enc_inp = Input(shape=(13, ))\n",
    "\n",
    "#embed = Embedding(VOCAB_SIZE+1, 50, mask_zero=True, input_length=13)(enc_inp)\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = Bidirectional(LSTM(400, return_state=True, dropout=0.05, return_sequences = True))\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "enc_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "dec_inp = Input(shape=(13, ))\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400*2, return_state=True, return_sequences=True, dropout=0.05)\n",
    "output, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "# attention\n",
    "attn_layer = AttentionLayer()\n",
    "attn_op, attn_state = attn_layer([encoder_outputs, output])\n",
    "decoder_concat_input = Concatenate(axis=-1)([output, attn_op])\n",
    "\n",
    "\n",
    "dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "final_output = dec_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], final_output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec4a57f5-b942-40ee-99dc-00d07200f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d59ec06a-b9af-46c2-b0c9-d2a9c5e0f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 11:55:33.637719: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-03-27 11:55:35.130830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:35.583154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:35.595333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:35.966030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:37.149307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:37.551926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:37.558351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 3.5625 - acc: 0.2605    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 11:55:39.566718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:39.690470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:39.699195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 11:55:39.908138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 2s/step - loss: 3.5625 - acc: 0.2605 - val_loss: 2.5836 - val_acc: 0.5000\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 2.3661 - acc: 0.5236 - val_loss: 2.0927 - val_acc: 0.5000\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 2.0219 - acc: 0.5285 - val_loss: 1.9968 - val_acc: 0.5000\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 1s 435ms/step - loss: 1.9136 - acc: 0.5285 - val_loss: 1.9191 - val_acc: 0.5385\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 1.8554 - acc: 0.5509 - val_loss: 1.8646 - val_acc: 0.5385\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 1.7868 - acc: 0.5608 - val_loss: 1.7331 - val_acc: 0.5577\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 1.7163 - acc: 0.5732 - val_loss: 1.6819 - val_acc: 0.5769\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 1.6561 - acc: 0.5881 - val_loss: 1.6240 - val_acc: 0.5962\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 1s 414ms/step - loss: 1.5887 - acc: 0.5906 - val_loss: 1.5983 - val_acc: 0.5769\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 1.5486 - acc: 0.6005 - val_loss: 1.5111 - val_acc: 0.5962\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 1s 436ms/step - loss: 1.4866 - acc: 0.5906 - val_loss: 1.4622 - val_acc: 0.6154\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.4384 - acc: 0.5980 - val_loss: 1.4017 - val_acc: 0.6154\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 1.3852 - acc: 0.5980 - val_loss: 1.3569 - val_acc: 0.6154\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.3173 - acc: 0.6179 - val_loss: 1.2715 - val_acc: 0.6538\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 1.2608 - acc: 0.6352 - val_loss: 1.2049 - val_acc: 0.6346\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.1954 - acc: 0.6452 - val_loss: 1.1308 - val_acc: 0.7115\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 1.1210 - acc: 0.6600 - val_loss: 1.0569 - val_acc: 0.7308\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 1.0446 - acc: 0.6898 - val_loss: 0.9813 - val_acc: 0.7500\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.9722 - acc: 0.7345 - val_loss: 0.9430 - val_acc: 0.7500\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.9018 - acc: 0.7444 - val_loss: 0.8772 - val_acc: 0.7308\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.8227 - acc: 0.7916 - val_loss: 0.7948 - val_acc: 0.7885\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.7654 - acc: 0.8040 - val_loss: 0.7611 - val_acc: 0.8077\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.6972 - acc: 0.8189 - val_loss: 0.6574 - val_acc: 0.8462\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.6262 - acc: 0.8536 - val_loss: 0.6288 - val_acc: 0.8462\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.5851 - acc: 0.8610 - val_loss: 0.5365 - val_acc: 0.9231\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.5356 - acc: 0.8710 - val_loss: 0.5163 - val_acc: 0.9423\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 0.4935 - acc: 0.8958 - val_loss: 0.4856 - val_acc: 0.9423\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.4475 - acc: 0.9007 - val_loss: 0.4393 - val_acc: 0.9423\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.4280 - acc: 0.9032 - val_loss: 0.6838 - val_acc: 0.8269\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.6364 - acc: 0.7916 - val_loss: 0.3832 - val_acc: 0.9231\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.4832 - acc: 0.8610 - val_loss: 0.4619 - val_acc: 0.8846\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.3934 - acc: 0.9107 - val_loss: 0.4222 - val_acc: 0.9038\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.4011 - acc: 0.9206 - val_loss: 0.3389 - val_acc: 0.9423\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.3476 - acc: 0.9330 - val_loss: 0.3311 - val_acc: 0.9615\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.3286 - acc: 0.9280 - val_loss: 0.3211 - val_acc: 0.9423\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.3031 - acc: 0.9280 - val_loss: 0.3011 - val_acc: 0.9423\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.2845 - acc: 0.9355 - val_loss: 0.2645 - val_acc: 0.9615\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.2614 - acc: 0.9454 - val_loss: 0.2486 - val_acc: 0.9615\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.2498 - acc: 0.9355 - val_loss: 0.2304 - val_acc: 0.9615\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.2242 - acc: 0.9529 - val_loss: 0.2137 - val_acc: 0.9615\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.2086 - acc: 0.9504 - val_loss: 0.1962 - val_acc: 0.9615\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.1975 - acc: 0.9504 - val_loss: 0.1832 - val_acc: 0.9615\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.1854 - acc: 0.9553 - val_loss: 0.1644 - val_acc: 0.9615\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.1717 - acc: 0.9529 - val_loss: 0.1456 - val_acc: 0.9808\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.1596 - acc: 0.9653 - val_loss: 0.1383 - val_acc: 0.9808\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.1512 - acc: 0.9653 - val_loss: 0.1284 - val_acc: 0.9808\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.1446 - acc: 0.9603 - val_loss: 0.1286 - val_acc: 0.9808\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.1362 - acc: 0.9653 - val_loss: 0.1159 - val_acc: 0.9808\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.1325 - acc: 0.9628 - val_loss: 0.1145 - val_acc: 0.9808\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.1228 - acc: 0.9628 - val_loss: 0.1126 - val_acc: 0.9808\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.1180 - acc: 0.9653 - val_loss: 0.1089 - val_acc: 0.9808\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.1169 - acc: 0.9727 - val_loss: 0.0974 - val_acc: 0.9615\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 0.1104 - acc: 0.9603 - val_loss: 0.0980 - val_acc: 0.9808\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 1s 345ms/step - loss: 0.1076 - acc: 0.9677 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.1045 - acc: 0.9727 - val_loss: 0.0846 - val_acc: 0.9808\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.0972 - acc: 0.9727 - val_loss: 0.0860 - val_acc: 0.9808\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 0.0966 - acc: 0.9702 - val_loss: 0.0901 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.0916 - acc: 0.9702 - val_loss: 0.0866 - val_acc: 0.9808\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.0929 - acc: 0.9727 - val_loss: 0.0794 - val_acc: 0.9808\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.0888 - acc: 0.9727 - val_loss: 0.0765 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.0845 - acc: 0.9727 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 0.0821 - acc: 0.9752 - val_loss: 0.0703 - val_acc: 0.9808\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.0833 - acc: 0.9727 - val_loss: 0.0645 - val_acc: 0.9808\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.0789 - acc: 0.9727 - val_loss: 0.0678 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.0803 - acc: 0.9702 - val_loss: 0.0682 - val_acc: 0.9808\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 1s 423ms/step - loss: 0.0758 - acc: 0.9727 - val_loss: 0.0690 - val_acc: 0.9808\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.0741 - acc: 0.9727 - val_loss: 0.0763 - val_acc: 0.9808\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.0767 - acc: 0.9702 - val_loss: 0.0676 - val_acc: 0.9808\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.0862 - acc: 0.9677 - val_loss: 0.1017 - val_acc: 0.9615\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.0907 - acc: 0.9677 - val_loss: 0.0866 - val_acc: 0.9808\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.0840 - acc: 0.9727 - val_loss: 0.0616 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.0898 - acc: 0.9628 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.0817 - acc: 0.9702 - val_loss: 0.0598 - val_acc: 0.9808\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 0.0795 - acc: 0.9677 - val_loss: 0.0898 - val_acc: 0.9808\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.0860 - acc: 0.9653 - val_loss: 0.1066 - val_acc: 0.9423\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.0798 - acc: 0.9702 - val_loss: 0.0916 - val_acc: 0.9423\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 0.0764 - acc: 0.9702 - val_loss: 0.0744 - val_acc: 0.9808\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.0767 - acc: 0.9628 - val_loss: 0.0629 - val_acc: 0.9808\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.0703 - acc: 0.9677 - val_loss: 0.0525 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 0.0697 - acc: 0.9702 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 0.0701 - acc: 0.9727 - val_loss: 0.0551 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.0681 - acc: 0.9727 - val_loss: 0.0529 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.0675 - acc: 0.9727 - val_loss: 0.0590 - val_acc: 0.9808\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.0678 - acc: 0.9702 - val_loss: 0.0647 - val_acc: 0.9808\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.0660 - acc: 0.9727 - val_loss: 0.0618 - val_acc: 0.9808\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 0.0656 - acc: 0.9752 - val_loss: 0.0578 - val_acc: 0.9808\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.0646 - acc: 0.9727 - val_loss: 0.0593 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 1s 421ms/step - loss: 0.0645 - acc: 0.9702 - val_loss: 0.0578 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 1s 421ms/step - loss: 0.0689 - acc: 0.9677 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 0.0665 - acc: 0.9702 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.0616 - acc: 0.9702 - val_loss: 0.0540 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.0653 - acc: 0.9702 - val_loss: 0.0587 - val_acc: 0.9808\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 0.0599 - acc: 0.9727 - val_loss: 0.0616 - val_acc: 0.9808\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 0.0634 - acc: 0.9702 - val_loss: 0.0617 - val_acc: 0.9808\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.0650 - acc: 0.9702 - val_loss: 0.0519 - val_acc: 0.9808\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.0623 - acc: 0.9677 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0617 - acc: 0.9677 - val_loss: 0.0521 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 0.0628 - acc: 0.9727 - val_loss: 0.0543 - val_acc: 0.9808\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 1s 433ms/step - loss: 0.0629 - acc: 0.9677 - val_loss: 0.0562 - val_acc: 0.9808\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 1s 414ms/step - loss: 0.0589 - acc: 0.9727 - val_loss: 0.0504 - val_acc: 0.9808\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 1s 434ms/step - loss: 0.0612 - acc: 0.9702 - val_loss: 0.0503 - val_acc: 0.9808\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 1s 417ms/step - loss: 0.0595 - acc: 0.9702 - val_loss: 0.0493 - val_acc: 0.9808\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.0593 - acc: 0.9727 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.0571 - acc: 0.9727 - val_loss: 0.0546 - val_acc: 0.9808\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 0.0618 - acc: 0.9677 - val_loss: 0.0543 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.0598 - acc: 0.9702 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.0580 - acc: 0.9702 - val_loss: 0.0494 - val_acc: 0.9808\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.0631 - acc: 0.9702 - val_loss: 0.0472 - val_acc: 0.9808\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 0.0599 - acc: 0.9702 - val_loss: 0.0546 - val_acc: 0.9808\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 0.0587 - acc: 0.9727 - val_loss: 0.0521 - val_acc: 0.9808\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.0621 - acc: 0.9727 - val_loss: 0.0537 - val_acc: 0.9808\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.0606 - acc: 0.9727 - val_loss: 0.0502 - val_acc: 0.9808\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.0624 - acc: 0.9677 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.0588 - acc: 0.9727 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.0582 - acc: 0.9727 - val_loss: 0.0511 - val_acc: 0.9808\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.0599 - acc: 0.9702 - val_loss: 0.0475 - val_acc: 0.9808\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 0.0611 - acc: 0.9727 - val_loss: 0.0507 - val_acc: 0.9808\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 0.0601 - acc: 0.9677 - val_loss: 0.0470 - val_acc: 0.9808\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0608 - acc: 0.9727 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.0619 - acc: 0.9702 - val_loss: 0.0570 - val_acc: 0.9808\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0634 - acc: 0.9727 - val_loss: 0.0506 - val_acc: 0.9808\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0623 - acc: 0.9653 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.0595 - acc: 0.9727 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 1s 345ms/step - loss: 0.0594 - acc: 0.9727 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 1s 344ms/step - loss: 0.0616 - acc: 0.9677 - val_loss: 0.0512 - val_acc: 0.9808\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0626 - acc: 0.9653 - val_loss: 0.0578 - val_acc: 0.9808\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.0580 - acc: 0.9702 - val_loss: 0.0586 - val_acc: 0.9808\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.0634 - acc: 0.9677 - val_loss: 0.0510 - val_acc: 0.9808\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 1s 431ms/step - loss: 0.0571 - acc: 0.9727 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.0593 - acc: 0.9702 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0602 - acc: 0.9727 - val_loss: 0.0414 - val_acc: 0.9808\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.0594 - acc: 0.9677 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0584 - acc: 0.9727 - val_loss: 0.0605 - val_acc: 0.9808\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0563 - acc: 0.9702 - val_loss: 0.0601 - val_acc: 0.9808\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0597 - acc: 0.9702 - val_loss: 0.0519 - val_acc: 0.9808\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0545 - acc: 0.9777 - val_loss: 0.0525 - val_acc: 0.9808\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.0558 - acc: 0.9727 - val_loss: 0.0459 - val_acc: 0.9808\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.0578 - acc: 0.9702 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.0588 - acc: 0.9727 - val_loss: 0.0464 - val_acc: 0.9808\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0575 - acc: 0.9727 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0562 - acc: 0.9727 - val_loss: 0.0525 - val_acc: 0.9808\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.0578 - acc: 0.9702 - val_loss: 0.0548 - val_acc: 0.9808\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0560 - acc: 0.9727 - val_loss: 0.0502 - val_acc: 0.9808\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0574 - acc: 0.9727 - val_loss: 0.0500 - val_acc: 0.9808\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0583 - acc: 0.9702 - val_loss: 0.0493 - val_acc: 0.9808\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.0546 - acc: 0.9727 - val_loss: 0.0494 - val_acc: 0.9808\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0615 - acc: 0.9653 - val_loss: 0.0542 - val_acc: 0.9808\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0569 - acc: 0.9702 - val_loss: 0.0462 - val_acc: 0.9808\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0569 - acc: 0.9727 - val_loss: 0.0470 - val_acc: 0.9808\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.0608 - acc: 0.9677 - val_loss: 0.0517 - val_acc: 0.9808\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.0564 - acc: 0.9752 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0415 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0558 - acc: 0.9727 - val_loss: 0.0407 - val_acc: 0.9808\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.0576 - acc: 0.9677 - val_loss: 0.0474 - val_acc: 0.9808\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0561 - acc: 0.9727 - val_loss: 0.0534 - val_acc: 0.9808\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0514 - val_acc: 0.9808\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0589 - acc: 0.9702 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.0577 - acc: 0.9702 - val_loss: 0.0450 - val_acc: 0.9808\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0452 - val_acc: 0.9808\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.0597 - acc: 0.9702 - val_loss: 0.0418 - val_acc: 0.9808\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0558 - acc: 0.9702 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0571 - acc: 0.9653 - val_loss: 0.0519 - val_acc: 0.9808\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0561 - acc: 0.9702 - val_loss: 0.0543 - val_acc: 0.9808\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0562 - acc: 0.9702 - val_loss: 0.0556 - val_acc: 0.9808\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0562 - acc: 0.9702 - val_loss: 0.0508 - val_acc: 0.9808\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0562 - acc: 0.9727 - val_loss: 0.0433 - val_acc: 0.9808\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0595 - acc: 0.9727 - val_loss: 0.0392 - val_acc: 0.9808\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0591 - acc: 0.9702 - val_loss: 0.0447 - val_acc: 0.9808\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0565 - acc: 0.9727 - val_loss: 0.0508 - val_acc: 0.9808\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0536 - acc: 0.9727 - val_loss: 0.0583 - val_acc: 0.9808\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0557 - acc: 0.9702 - val_loss: 0.0584 - val_acc: 0.9615\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.0558 - acc: 0.9677 - val_loss: 0.0483 - val_acc: 0.9808\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0536 - acc: 0.9752 - val_loss: 0.0397 - val_acc: 0.9808\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0550 - acc: 0.9727 - val_loss: 0.0403 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0575 - acc: 0.9727 - val_loss: 0.0442 - val_acc: 0.9808\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0575 - acc: 0.9702 - val_loss: 0.0521 - val_acc: 0.9808\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.0584 - acc: 0.9702 - val_loss: 0.0527 - val_acc: 0.9808\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0555 - acc: 0.9752 - val_loss: 0.0535 - val_acc: 0.9808\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0565 - acc: 0.9702 - val_loss: 0.0535 - val_acc: 0.9808\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0557 - acc: 0.9727 - val_loss: 0.0449 - val_acc: 0.9808\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.0564 - acc: 0.9727 - val_loss: 0.0434 - val_acc: 0.9808\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0548 - acc: 0.9702 - val_loss: 0.0442 - val_acc: 0.9808\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0575 - acc: 0.9702 - val_loss: 0.0418 - val_acc: 0.9808\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0559 - acc: 0.9727 - val_loss: 0.0433 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0580 - acc: 0.9702 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0561 - acc: 0.9727 - val_loss: 0.0509 - val_acc: 0.9808\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0575 - acc: 0.9677 - val_loss: 0.0510 - val_acc: 0.9808\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.0536 - acc: 0.9702 - val_loss: 0.0525 - val_acc: 0.9808\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0582 - acc: 0.9702 - val_loss: 0.0539 - val_acc: 0.9615\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0582 - acc: 0.9702 - val_loss: 0.0489 - val_acc: 0.9808\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0559 - acc: 0.9677 - val_loss: 0.0468 - val_acc: 0.9808\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0566 - acc: 0.9702 - val_loss: 0.0481 - val_acc: 0.9615\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0589 - acc: 0.9628 - val_loss: 0.0486 - val_acc: 0.9615\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0558 - acc: 0.9677 - val_loss: 0.0469 - val_acc: 0.9808\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0557 - acc: 0.9702 - val_loss: 0.0438 - val_acc: 0.9808\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0549 - acc: 0.9727 - val_loss: 0.0451 - val_acc: 0.9808\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0594 - acc: 0.9702 - val_loss: 0.0467 - val_acc: 0.9808\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0597 - acc: 0.9677 - val_loss: 0.0492 - val_acc: 0.9808\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0508 - val_acc: 0.9808\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0566 - acc: 0.9702 - val_loss: 0.0558 - val_acc: 0.9615\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0582 - acc: 0.9702 - val_loss: 0.0539 - val_acc: 0.9808\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0592 - acc: 0.9702 - val_loss: 0.0511 - val_acc: 0.9808\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0572 - acc: 0.9677 - val_loss: 0.0482 - val_acc: 0.9808\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0537 - acc: 0.9752 - val_loss: 0.0515 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.0575 - acc: 0.9702 - val_loss: 0.0527 - val_acc: 0.9615\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0627 - acc: 0.9628 - val_loss: 0.0403 - val_acc: 0.9808\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0572 - acc: 0.9727 - val_loss: 0.0382 - val_acc: 0.9808\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0581 - acc: 0.9702 - val_loss: 0.0409 - val_acc: 0.9808\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0555 - acc: 0.9752 - val_loss: 0.0429 - val_acc: 0.9808\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.0576 - acc: 0.9677 - val_loss: 0.0536 - val_acc: 0.9808\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.0566 - acc: 0.9677 - val_loss: 0.0557 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0573 - acc: 0.9677 - val_loss: 0.0497 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0568 - acc: 0.9702 - val_loss: 0.0433 - val_acc: 0.9808\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0566 - acc: 0.9752 - val_loss: 0.0408 - val_acc: 0.9808\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0553 - acc: 0.9702 - val_loss: 0.0440 - val_acc: 0.9808\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0579 - acc: 0.9727 - val_loss: 0.0447 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0558 - acc: 0.9727 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0550 - acc: 0.9702 - val_loss: 0.0496 - val_acc: 0.9808\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0539 - acc: 0.9727 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0555 - acc: 0.9677 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0536 - acc: 0.9727 - val_loss: 0.0462 - val_acc: 0.9808\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.0544 - acc: 0.9702 - val_loss: 0.0443 - val_acc: 0.9808\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0539 - acc: 0.9727 - val_loss: 0.0425 - val_acc: 0.9808\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0571 - acc: 0.9702 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0571 - acc: 0.9752 - val_loss: 0.0455 - val_acc: 0.9808\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0573 - acc: 0.9727 - val_loss: 0.0479 - val_acc: 0.9808\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0487 - val_acc: 0.9808\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0609 - acc: 0.9677 - val_loss: 0.0503 - val_acc: 0.9808\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0565 - acc: 0.9727 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0561 - acc: 0.9702 - val_loss: 0.0446 - val_acc: 0.9808\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0561 - acc: 0.9702 - val_loss: 0.0413 - val_acc: 0.9808\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0534 - acc: 0.9702 - val_loss: 0.0409 - val_acc: 0.9808\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0555 - acc: 0.9727 - val_loss: 0.0448 - val_acc: 0.9808\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.0556 - acc: 0.9727 - val_loss: 0.0505 - val_acc: 0.9808\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0534 - acc: 0.9752 - val_loss: 0.0549 - val_acc: 0.9808\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0574 - acc: 0.9727 - val_loss: 0.0552 - val_acc: 0.9808\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0559 - acc: 0.9677 - val_loss: 0.0492 - val_acc: 0.9808\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0587 - acc: 0.9702 - val_loss: 0.0415 - val_acc: 0.9808\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0552 - acc: 0.9677 - val_loss: 0.0403 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0569 - acc: 0.9727 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0544 - acc: 0.9702 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0553 - acc: 0.9702 - val_loss: 0.0530 - val_acc: 0.9808\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0555 - acc: 0.9727 - val_loss: 0.0558 - val_acc: 0.9808\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0573 - acc: 0.9727 - val_loss: 0.0470 - val_acc: 0.9808\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0565 - acc: 0.9702 - val_loss: 0.0459 - val_acc: 0.9808\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0569 - acc: 0.9727 - val_loss: 0.0429 - val_acc: 0.9808\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0550 - acc: 0.9702 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0531 - acc: 0.9702 - val_loss: 0.0518 - val_acc: 0.9808\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0560 - acc: 0.9702 - val_loss: 0.0522 - val_acc: 0.9808\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0551 - acc: 0.9727 - val_loss: 0.0563 - val_acc: 0.9808\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0559 - acc: 0.9702 - val_loss: 0.0511 - val_acc: 0.9808\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0559 - acc: 0.9702 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0542 - acc: 0.9752 - val_loss: 0.0465 - val_acc: 0.9808\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0549 - acc: 0.9702 - val_loss: 0.0468 - val_acc: 0.9808\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0539 - acc: 0.9727 - val_loss: 0.0475 - val_acc: 0.9808\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0537 - acc: 0.9727 - val_loss: 0.0458 - val_acc: 0.9808\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0564 - acc: 0.9702 - val_loss: 0.0446 - val_acc: 0.9808\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0540 - acc: 0.9702 - val_loss: 0.0420 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0553 - acc: 0.9752 - val_loss: 0.0498 - val_acc: 0.9808\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0537 - acc: 0.9702 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0549 - acc: 0.9702 - val_loss: 0.0467 - val_acc: 0.9808\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0556 - acc: 0.9702 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0566 - acc: 0.9727 - val_loss: 0.0448 - val_acc: 0.9808\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0468 - val_acc: 0.9808\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0526 - acc: 0.9752 - val_loss: 0.0494 - val_acc: 0.9808\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0560 - acc: 0.9727 - val_loss: 0.0538 - val_acc: 0.9615\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0590 - acc: 0.9653 - val_loss: 0.0513 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0580 - acc: 0.9628 - val_loss: 0.0484 - val_acc: 0.9808\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0560 - acc: 0.9702 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0558 - acc: 0.9727 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0537 - acc: 0.9727 - val_loss: 0.0399 - val_acc: 0.9808\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0578 - acc: 0.9653 - val_loss: 0.0476 - val_acc: 0.9808\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0537 - acc: 0.9702 - val_loss: 0.0527 - val_acc: 0.9808\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0520 - val_acc: 0.9615\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0562 - acc: 0.9727 - val_loss: 0.0497 - val_acc: 0.9615\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0548 - acc: 0.9677 - val_loss: 0.0446 - val_acc: 0.9808\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0524 - acc: 0.9702 - val_loss: 0.0469 - val_acc: 0.9808\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0551 - acc: 0.9752 - val_loss: 0.0469 - val_acc: 0.9808\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0567 - acc: 0.9702 - val_loss: 0.0485 - val_acc: 0.9808\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0549 - acc: 0.9727 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0551 - acc: 0.9727 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0555 - acc: 0.9727 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0543 - acc: 0.9727 - val_loss: 0.0435 - val_acc: 0.9808\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0544 - acc: 0.9727 - val_loss: 0.0483 - val_acc: 0.9808\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0558 - acc: 0.9702 - val_loss: 0.0519 - val_acc: 0.9808\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0541 - acc: 0.9752 - val_loss: 0.0537 - val_acc: 0.9808\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.0551 - acc: 0.9752 - val_loss: 0.0474 - val_acc: 0.9808\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0567 - acc: 0.9727 - val_loss: 0.0424 - val_acc: 0.9808\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0564 - acc: 0.9702 - val_loss: 0.0401 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.0550 - acc: 0.9752 - val_loss: 0.0410 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0462 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0541 - acc: 0.9727 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0548 - acc: 0.9727 - val_loss: 0.0465 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0533 - acc: 0.9727 - val_loss: 0.0444 - val_acc: 0.9808\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0535 - acc: 0.9702 - val_loss: 0.0440 - val_acc: 0.9808\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0534 - acc: 0.9752 - val_loss: 0.0445 - val_acc: 0.9808\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0587 - acc: 0.9702 - val_loss: 0.0483 - val_acc: 0.9808\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0531 - acc: 0.9752 - val_loss: 0.0481 - val_acc: 0.9808\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0571 - acc: 0.9702 - val_loss: 0.0480 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0564 - acc: 0.9702 - val_loss: 0.0465 - val_acc: 0.9808\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0562 - acc: 0.9702 - val_loss: 0.0440 - val_acc: 0.9808\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0561 - acc: 0.9727 - val_loss: 0.0426 - val_acc: 0.9808\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0547 - acc: 0.9727 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0532 - acc: 0.9677 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0546 - acc: 0.9702 - val_loss: 0.0459 - val_acc: 0.9808\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0569 - acc: 0.9727 - val_loss: 0.0461 - val_acc: 0.9808\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0551 - acc: 0.9727 - val_loss: 0.0451 - val_acc: 0.9808\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0547 - acc: 0.9727 - val_loss: 0.0483 - val_acc: 0.9808\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0543 - acc: 0.9677 - val_loss: 0.0525 - val_acc: 0.9808\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0560 - acc: 0.9702 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0552 - acc: 0.9702 - val_loss: 0.0477 - val_acc: 0.9808\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0552 - acc: 0.9752 - val_loss: 0.0444 - val_acc: 0.9808\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.0540 - acc: 0.9727 - val_loss: 0.0472 - val_acc: 0.9808\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0551 - acc: 0.9677 - val_loss: 0.0493 - val_acc: 0.9808\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0531 - acc: 0.9727 - val_loss: 0.0491 - val_acc: 0.9808\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0529 - acc: 0.9702 - val_loss: 0.0488 - val_acc: 0.9808\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0445 - val_acc: 0.9808\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.0530 - acc: 0.9702 - val_loss: 0.0433 - val_acc: 0.9808\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0521 - acc: 0.9702 - val_loss: 0.0420 - val_acc: 0.9808\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0449 - val_acc: 0.9808\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.0544 - acc: 0.9752 - val_loss: 0.0446 - val_acc: 0.9808\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0536 - acc: 0.9727 - val_loss: 0.0503 - val_acc: 0.9808\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0533 - acc: 0.9702 - val_loss: 0.0547 - val_acc: 0.9808\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0546 - acc: 0.9727 - val_loss: 0.0551 - val_acc: 0.9808\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0544 - acc: 0.9727 - val_loss: 0.0485 - val_acc: 0.9808\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0554 - acc: 0.9702 - val_loss: 0.0398 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0575 - acc: 0.9702 - val_loss: 0.0401 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0541 - acc: 0.9727 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0552 - acc: 0.9727 - val_loss: 0.0451 - val_acc: 0.9808\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0538 - acc: 0.9727 - val_loss: 0.0496 - val_acc: 0.9808\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0522 - acc: 0.9727 - val_loss: 0.0525 - val_acc: 0.9808\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.0551 - acc: 0.9727 - val_loss: 0.0488 - val_acc: 0.9808\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0527 - acc: 0.9727 - val_loss: 0.0471 - val_acc: 0.9808\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0561 - acc: 0.9702 - val_loss: 0.0460 - val_acc: 0.9808\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0536 - acc: 0.9702 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.0562 - acc: 0.9727 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0441 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0520 - acc: 0.9702 - val_loss: 0.0424 - val_acc: 0.9808\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0551 - acc: 0.9727 - val_loss: 0.0405 - val_acc: 0.9808\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0563 - acc: 0.9702 - val_loss: 0.0411 - val_acc: 0.9808\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0563 - acc: 0.9727 - val_loss: 0.0427 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0550 - acc: 0.9702 - val_loss: 0.0489 - val_acc: 0.9808\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0550 - acc: 0.9727 - val_loss: 0.0513 - val_acc: 0.9808\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0550 - acc: 0.9727 - val_loss: 0.0551 - val_acc: 0.9808\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0533 - acc: 0.9702 - val_loss: 0.0526 - val_acc: 0.9808\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0539 - acc: 0.9727 - val_loss: 0.0472 - val_acc: 0.9808\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0561 - acc: 0.9727 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0554 - acc: 0.9702 - val_loss: 0.0384 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0565 - acc: 0.9727 - val_loss: 0.0404 - val_acc: 0.9808\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0537 - acc: 0.9752 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0526 - acc: 0.9727 - val_loss: 0.0462 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0535 - acc: 0.9727 - val_loss: 0.0505 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0554 - acc: 0.9702 - val_loss: 0.0507 - val_acc: 0.9808\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0560 - acc: 0.9702 - val_loss: 0.0463 - val_acc: 0.9808\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0558 - acc: 0.9727 - val_loss: 0.0479 - val_acc: 0.9808\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0522 - acc: 0.9727 - val_loss: 0.0475 - val_acc: 0.9808\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0545 - acc: 0.9702 - val_loss: 0.0458 - val_acc: 0.9808\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0461 - val_acc: 0.9808\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0520 - acc: 0.9702 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0536 - acc: 0.9727 - val_loss: 0.0487 - val_acc: 0.9808\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0581 - acc: 0.9677 - val_loss: 0.0447 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0436 - val_acc: 0.9808\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0543 - acc: 0.9752 - val_loss: 0.0431 - val_acc: 0.9808\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0559 - acc: 0.9727 - val_loss: 0.0460 - val_acc: 0.9808\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0548 - acc: 0.9727 - val_loss: 0.0437 - val_acc: 0.9808\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0540 - acc: 0.9702 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0509 - val_acc: 0.9808\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0537 - acc: 0.9727 - val_loss: 0.0484 - val_acc: 0.9808\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0545 - acc: 0.9702 - val_loss: 0.0414 - val_acc: 0.9808\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0545 - acc: 0.9702 - val_loss: 0.0427 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0556 - acc: 0.9727 - val_loss: 0.0433 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0545 - acc: 0.9702 - val_loss: 0.0469 - val_acc: 0.9808\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0567 - acc: 0.9702 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0549 - acc: 0.9727 - val_loss: 0.0464 - val_acc: 0.9808\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0538 - acc: 0.9727 - val_loss: 0.0481 - val_acc: 0.9808\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0555 - acc: 0.9702 - val_loss: 0.0481 - val_acc: 0.9615\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0531 - acc: 0.9727 - val_loss: 0.0461 - val_acc: 0.9808\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0546 - acc: 0.9702 - val_loss: 0.0459 - val_acc: 0.9808\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0563 - acc: 0.9702 - val_loss: 0.0466 - val_acc: 0.9808\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0533 - acc: 0.9677 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0531 - acc: 0.9727 - val_loss: 0.0443 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0555 - acc: 0.9727 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0536 - acc: 0.9752 - val_loss: 0.0460 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0540 - acc: 0.9727 - val_loss: 0.0459 - val_acc: 0.9808\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0472 - val_acc: 0.9808\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0563 - acc: 0.9702 - val_loss: 0.0479 - val_acc: 0.9808\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0550 - acc: 0.9702 - val_loss: 0.0451 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0529 - acc: 0.9727 - val_loss: 0.0469 - val_acc: 0.9808\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0562 - acc: 0.9702 - val_loss: 0.0454 - val_acc: 0.9808\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0469 - val_acc: 0.9808\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 1s 414ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0471 - val_acc: 0.9808\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 1s 427ms/step - loss: 0.0533 - acc: 0.9727 - val_loss: 0.0485 - val_acc: 0.9808\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.0541 - acc: 0.9702 - val_loss: 0.0489 - val_acc: 0.9808\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0554 - acc: 0.9727 - val_loss: 0.0488 - val_acc: 0.9808\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0553 - acc: 0.9702 - val_loss: 0.0458 - val_acc: 0.9808\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.0529 - acc: 0.9727 - val_loss: 0.0406 - val_acc: 0.9808\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.0550 - acc: 0.9752 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0535 - acc: 0.9727 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0526 - acc: 0.9702 - val_loss: 0.0449 - val_acc: 0.9808\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0548 - acc: 0.9702 - val_loss: 0.0494 - val_acc: 0.9808\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0541 - acc: 0.9727 - val_loss: 0.0515 - val_acc: 0.9808\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0533 - acc: 0.9727 - val_loss: 0.0473 - val_acc: 0.9808\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0545 - acc: 0.9727 - val_loss: 0.0438 - val_acc: 0.9808\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0557 - acc: 0.9752 - val_loss: 0.0454 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0525 - acc: 0.9702 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.0566 - acc: 0.9727 - val_loss: 0.0445 - val_acc: 0.9808\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0467 - val_acc: 0.9808\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0536 - acc: 0.9727 - val_loss: 0.0466 - val_acc: 0.9808\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0552 - acc: 0.9702 - val_loss: 0.0462 - val_acc: 0.9808\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0553 - acc: 0.9702 - val_loss: 0.0450 - val_acc: 0.9808\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0567 - acc: 0.9702 - val_loss: 0.0441 - val_acc: 0.9808\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0529 - acc: 0.9727 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0539 - acc: 0.9702 - val_loss: 0.0485 - val_acc: 0.9808\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0546 - acc: 0.9702 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.0550 - acc: 0.9727 - val_loss: 0.0492 - val_acc: 0.9808\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0455 - val_acc: 0.9808\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0535 - acc: 0.9727 - val_loss: 0.0420 - val_acc: 0.9808\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.0520 - acc: 0.9752 - val_loss: 0.0428 - val_acc: 0.9808\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0551 - acc: 0.9702 - val_loss: 0.0447 - val_acc: 0.9808\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.0539 - acc: 0.9702 - val_loss: 0.0422 - val_acc: 0.9808\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0535 - acc: 0.9727 - val_loss: 0.0416 - val_acc: 0.9808\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0539 - acc: 0.9702 - val_loss: 0.0452 - val_acc: 0.9808\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0529 - acc: 0.9727 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0548 - acc: 0.9702 - val_loss: 0.0485 - val_acc: 0.9808\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0527 - acc: 0.9727 - val_loss: 0.0521 - val_acc: 0.9808\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0543 - acc: 0.9702 - val_loss: 0.0502 - val_acc: 0.9808\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.0551 - acc: 0.9702 - val_loss: 0.0430 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0535 - acc: 0.9727 - val_loss: 0.0365 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0395 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0549 - acc: 0.9727 - val_loss: 0.0433 - val_acc: 0.9808\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0521 - acc: 0.9752 - val_loss: 0.0472 - val_acc: 0.9808\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0542 - acc: 0.9702 - val_loss: 0.0539 - val_acc: 0.9808\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0545 - acc: 0.9702 - val_loss: 0.0540 - val_acc: 0.9808\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0478 - val_acc: 0.9808\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0541 - acc: 0.9727 - val_loss: 0.0461 - val_acc: 0.9808\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0541 - acc: 0.9727 - val_loss: 0.0433 - val_acc: 0.9808\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0539 - acc: 0.9727 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0537 - acc: 0.9702 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0511 - acc: 0.9702 - val_loss: 0.0441 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0542 - acc: 0.9702 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0546 - acc: 0.9727 - val_loss: 0.0416 - val_acc: 0.9808\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0516 - acc: 0.9702 - val_loss: 0.0442 - val_acc: 0.9808\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0533 - acc: 0.9702 - val_loss: 0.0513 - val_acc: 0.9808\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0557 - acc: 0.9727 - val_loss: 0.0529 - val_acc: 0.9808\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.0551 - acc: 0.9727 - val_loss: 0.0528 - val_acc: 0.9808\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0547 - acc: 0.9677 - val_loss: 0.0514 - val_acc: 0.9808\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0521 - acc: 0.9727 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0569 - acc: 0.9727 - val_loss: 0.0453 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0542 - acc: 0.9727 - val_loss: 0.0468 - val_acc: 0.9808\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0558 - acc: 0.9702 - val_loss: 0.0452 - val_acc: 0.9808\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0540 - acc: 0.9702 - val_loss: 0.0426 - val_acc: 0.9808\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.0539 - acc: 0.9727 - val_loss: 0.0447 - val_acc: 0.9808\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0533 - acc: 0.9727 - val_loss: 0.0476 - val_acc: 0.9808\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0551 - acc: 0.9702 - val_loss: 0.0503 - val_acc: 0.9808\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0525 - acc: 0.9727 - val_loss: 0.0500 - val_acc: 0.9808\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.0529 - acc: 0.9727 - val_loss: 0.0455 - val_acc: 0.9808\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.0570 - acc: 0.9727 - val_loss: 0.0488 - val_acc: 0.9808\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0553 - acc: 0.9702 - val_loss: 0.0478 - val_acc: 0.9808\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0550 - acc: 0.9653 - val_loss: 0.0434 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0540 - acc: 0.9727 - val_loss: 0.0445 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.0545 - acc: 0.9702 - val_loss: 0.0462 - val_acc: 0.9808\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0554 - acc: 0.9677 - val_loss: 0.0441 - val_acc: 0.9808\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0454 - val_acc: 0.9808\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0554 - acc: 0.9702 - val_loss: 0.0475 - val_acc: 0.9808\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0547 - acc: 0.9702 - val_loss: 0.0461 - val_acc: 0.9808\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.0532 - acc: 0.9727 - val_loss: 0.0466 - val_acc: 0.9808\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0550 - acc: 0.9727 - val_loss: 0.0473 - val_acc: 0.9808\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.0549 - acc: 0.9727 - val_loss: 0.0484 - val_acc: 0.9808\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0530 - acc: 0.9727 - val_loss: 0.0483 - val_acc: 0.9808\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0532 - acc: 0.9702 - val_loss: 0.0470 - val_acc: 0.9808\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0537 - acc: 0.9727 - val_loss: 0.0466 - val_acc: 0.9808\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0555 - acc: 0.9752 - val_loss: 0.0455 - val_acc: 0.9808\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0537 - acc: 0.9727 - val_loss: 0.0438 - val_acc: 0.9808\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0565 - acc: 0.9702 - val_loss: 0.0445 - val_acc: 0.9808\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0534 - acc: 0.9727 - val_loss: 0.0463 - val_acc: 0.9808\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.0554 - acc: 0.9702 - val_loss: 0.0497 - val_acc: 0.9808\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0558 - acc: 0.9653 - val_loss: 0.0445 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0458 - val_acc: 0.9808\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.0536 - acc: 0.9727 - val_loss: 0.0462 - val_acc: 0.9808\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0524 - acc: 0.9727 - val_loss: 0.0456 - val_acc: 0.9808\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.0526 - acc: 0.9702 - val_loss: 0.0455 - val_acc: 0.9808\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.0552 - acc: 0.9727 - val_loss: 0.0474 - val_acc: 0.9808\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0521 - acc: 0.9727 - val_loss: 0.0453 - val_acc: 0.9808\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.0547 - acc: 0.9727 - val_loss: 0.0426 - val_acc: 0.9808\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0558 - acc: 0.9702 - val_loss: 0.0438 - val_acc: 0.9808\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.0555 - acc: 0.9702 - val_loss: 0.0437 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0532 - acc: 0.9727 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0560 - acc: 0.9727 - val_loss: 0.0438 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.0553 - acc: 0.9727 - val_loss: 0.0439 - val_acc: 0.9808\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.0556 - acc: 0.9727 - val_loss: 0.0477 - val_acc: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16de287c0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=500, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "014e9f2f-b0a9-4d50-837f-7013943c7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbot.h5')\n",
    "model.save_weights('chatbot_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b727067e-0bb6-4e78-b4c6-4f74c5f7deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference\n",
    "enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5605ddfd-ab41-4f28-b107-b3d5789c00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = tf.keras.layers.Input(shape=( 400 * 2,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=( 400 * 2,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , initial_state=decoder_states_inputs)\n",
    "\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "#decoder_output = dec_dense(decoder_outputs)\n",
    "\n",
    "dec_model = Model([dec_inp, decoder_states_inputs],\n",
    "                                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31602f72-2190-435d-8074-5a8c7d149cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#       start chatting version. 1.0      #\n",
      "##########################################\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "you :  best food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 12:35:24.016092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-27 12:35:24.048843: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "chatbot attention :  sushi is the <PAD> food ever \n",
      "==============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "you :  which colour do you like ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "chatbot attention :  i am 29 years old \n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"#       start chatting version. 1.0      #\")\n",
    "print(\"##########################################\")\n",
    "\n",
    "\n",
    "prepro1 = \"\"\n",
    "while prepro1 != 'q':\n",
    "    \n",
    "    prepro1 = input(\"you : \")\n",
    "    try:\n",
    "        prepro1 = clean_text(prepro1)\n",
    "        prepro = [prepro1]\n",
    "        \n",
    "        txt = []\n",
    "        for x in prepro:\n",
    "            lst = []\n",
    "            for y in x.split():\n",
    "                try:\n",
    "                    lst.append(vocab[y])\n",
    "                except:\n",
    "                    lst.append(vocab['<OUT>'])\n",
    "            txt.append(lst)\n",
    "        txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "\n",
    "        ###\n",
    "        enc_op, stat = enc_model.predict( txt )\n",
    "\n",
    "        empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "        empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "        stop_condition = False\n",
    "        decoded_translation = ''\n",
    "\n",
    "\n",
    "        while not stop_condition :\n",
    "\n",
    "            dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + stat )\n",
    "\n",
    "            ###\n",
    "            ###########################\n",
    "            attn_op, attn_state = attn_layer([enc_op, dec_outputs])\n",
    "            decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n",
    "            decoder_concat_input = dec_dense(decoder_concat_input)\n",
    "            ###########################\n",
    "\n",
    "            sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
    "\n",
    "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "            if sampled_word != '<EOS> ':\n",
    "                decoded_translation += sampled_word           \n",
    "\n",
    "\n",
    "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "                stop_condition = True\n",
    "\n",
    "            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "            empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "            stat = [ h , c ] \n",
    "\n",
    "        print(\"chatbot attention : \", decoded_translation )\n",
    "        print(\"==============================================\")\n",
    "\n",
    "    except:\n",
    "        print(\"sorry didn't got you , please type again :( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2fa9da-eb37-4cda-9e3d-ed835546305f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
