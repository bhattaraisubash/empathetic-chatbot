{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aec5657-a750-4afe-9a0f-b42911ea5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765c5834-e96f-47d0-9b21-64b1fe8d55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87c6c29-2460-4b33-ad82-6de64996b990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>4</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>5</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "1  hit:0_conv:1              2  sentimental   \n",
       "2  hit:0_conv:1              3  sentimental   \n",
       "3  hit:0_conv:1              4  sentimental   \n",
       "4  hit:0_conv:1              5  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "1  I remember going to the fireworks with my best...            0   \n",
       "2  I remember going to the fireworks with my best...            1   \n",
       "3  I remember going to the fireworks with my best...            0   \n",
       "4  I remember going to the fireworks with my best...            1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5  NaN  \n",
       "1  Was this a friend you were in love with_comma_...  5|5|5_2|2|5  NaN  \n",
       "2                This was a best friend. I miss her.  5|5|5_2|2|5  NaN  \n",
       "3                                Where has she gone?  5|5|5_2|2|5  NaN  \n",
       "4                                 We no longer talk.  5|5|5_2|2|5  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../dataset/empatheticdialogues/train.csv', on_bad_lines='skip')\n",
    "valid = pd.read_csv('../dataset/empatheticdialogues/valid.csv', on_bad_lines='skip')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2667b0-f6d2-4127-b28f-3c80724086c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_train = train['prompt']\n",
    "utterance_train = train['utterance']\n",
    "context_train = train['context']\n",
    "\n",
    "prompt_valid = valid['prompt']\n",
    "utterance_valid = valid['utterance']\n",
    "context_valid = valid['context']\n",
    "del (train, valid)\n",
    "len(prompt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c5e392-70f7-4a38-b500-942d59f469a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentimental', 'afraid', 'proud', 'faithful', 'terrified',\n",
       "       'joyful', 'angry', 'sad', 'jealous', 'grateful', 'prepared',\n",
       "       'embarrassed', 'excited', 'annoyed', 'lonely', 'ashamed', 'guilty',\n",
       "       'surprised', 'nostalgic', 'confident', 'furious', 'disappointed',\n",
       "       'caring', 'trusting', 'disgusted', 'anticipating', 'anxious',\n",
       "       'hopeful', 'content', 'impressed', 'apprehensive', 'devastated'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df34c3de-b131-4bd6-a31b-9ab8a569649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the max length <-- this is character length including spaces\n",
    "MAX_LENGTH = 23\n",
    "trimmed_prompt_train = []\n",
    "trimmed_utterance_train = []\n",
    "trimmed_context_train = []\n",
    "for i in range(len(prompt_train)):\n",
    "    #trim dataset to the MAX_LENGTH range [0, MAX_LENGTH]\n",
    "    trimmed_prompt_train.append(prompt_train[i][:MAX_LENGTH].strip())\n",
    "    trimmed_utterance_train.append(utterance_train[i].strip())\n",
    "    trimmed_context_train.append(context_train[i].strip())\n",
    "\n",
    "trimmed_prompt_valid = []\n",
    "trimmed_utterance_valid = []\n",
    "trimmed_context_valid = []\n",
    "for i in range(len(prompt_valid)):\n",
    "    trimmed_prompt_valid.append(prompt_valid[i][:MAX_LENGTH].strip())\n",
    "    trimmed_utterance_valid.append(utterance_valid[i].strip())\n",
    "    trimmed_context_valid.append(context_valid[i].strip())\n",
    "\n",
    "del (prompt_train, prompt_valid, utterance_train, utterance_valid, context_train, context_valid, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e83ec3-beba-4d42-a60f-687b76c329b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76668"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trimmed_prompt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca641777-b198-4a1d-986b-3e525c7ee7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions_and_clean(text):\n",
    "    # mapping of contractions to their expanded forms\n",
    "    contractions = {\n",
    "        r\"i'm\": \"i am\",\n",
    "        r\"he's\": \"he is\",\n",
    "        r\"she's\": \"she is\",\n",
    "        r\"that's\": \"that is\",\n",
    "        r\"what's\": \"what is\",\n",
    "        r\"where's\": \"where is\",\n",
    "        r\"\\'ll\": \" will\",\n",
    "        r\"\\'ve\": \" have\",\n",
    "        r\"\\'re\": \" are\",\n",
    "        r\"\\'d\": \" would\",\n",
    "        r\"won't\": \"will not\",\n",
    "        r\"can't\": \"can not\",\n",
    "    }\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = re.sub(contraction, expansion, text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4581ae6d-f14a-4ece-b836-2a6760d3f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_prompt_train = []\n",
    "cleaned_utterance_train = []\n",
    "for line in trimmed_prompt_train:\n",
    "    cleaned_prompt_train.append(expand_contractions_and_clean(line))\n",
    "        \n",
    "for line in trimmed_utterance_train:\n",
    "    cleaned_utterance_train.append(expand_contractions_and_clean(line))\n",
    "\n",
    "cleaned_prompt_valid = []\n",
    "cleaned_utterance_valid = []\n",
    "for line in trimmed_prompt_valid:\n",
    "    cleaned_prompt_valid.append(expand_contractions_and_clean(line))\n",
    "        \n",
    "for line in trimmed_utterance_valid:\n",
    "    cleaned_utterance_valid.append(expand_contractions_and_clean(line))\n",
    "\n",
    "del (trimmed_prompt_train, trimmed_utterance_train, trimmed_prompt_valid, trimmed_utterance_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902d98c7-d509-4dd2-9ffe-2d873a615825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting words\n",
    "word_count = {}\n",
    "#for train\n",
    "for line in cleaned_prompt_train:\n",
    "    for word in line.split():\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "\n",
    "del (line, word)\n",
    "\n",
    "for line in cleaned_utterance_train:\n",
    "    for word in line.split():\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "\n",
    "del (line, word)\n",
    "\n",
    "#for valid\n",
    "for line in cleaned_prompt_valid:\n",
    "    for word in line.split():\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "\n",
    "del (line, word)\n",
    "\n",
    "for line in cleaned_utterance_valid:\n",
    "    for word in line.split():\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "\n",
    "del (line, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441fb10d-73cf-457c-a1ee-766c112d1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#omit less frequent words\n",
    "threshold = 5\n",
    "\n",
    "vocab = {}\n",
    "num = 0\n",
    "for word, count in word_count.items():\n",
    "    if count >= threshold:\n",
    "        vocab[word] = num\n",
    "        num += 1\n",
    "\n",
    "del(word, count, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e7ecf4-1733-42c8-b697-63ce95ed5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>', '<SEP>']\n",
    "for i in range(len(cleaned_utterance_train)):\n",
    "    cleaned_utterance_train[i] = '<SOS> ' + cleaned_utterance_train[i] + ' <EOS>'\n",
    "del(i)\n",
    "\n",
    "for i in range(len(cleaned_utterance_valid)):\n",
    "    cleaned_utterance_valid[i] = '<SOS> ' + cleaned_utterance_valid[i] + ' <EOS>'\n",
    "del(i)\n",
    "\n",
    "for i in range(len(cleaned_prompt_train)):\n",
    "    cleaned_prompt_train[i] = cleaned_prompt_train[i] + ' <SEP> ' + trimmed_context_train[i]\n",
    "del(i)\n",
    "\n",
    "for i in range(len(cleaned_prompt_valid)):\n",
    "    cleaned_prompt_valid[i] = cleaned_prompt_valid[i] + ' <SEP> ' + trimmed_context_valid[i]\n",
    "del(i)\n",
    "\n",
    "#for context words <-- here because don't want to lose context by threshold\n",
    "for word in trimmed_context_train:\n",
    "    if word not in vocab:\n",
    "        vocab[word] = len(vocab)\n",
    "del (word)\n",
    "\n",
    "for word in trimmed_context_valid:\n",
    "    if word not in vocab:\n",
    "        vocab[word] = len(vocab)\n",
    "del (word)\n",
    "\n",
    "#for tokens\n",
    "for token in tokens:\n",
    "    if token not in vocab:\n",
    "        vocab[token] = len(vocab)\n",
    "del(token)\n",
    "\n",
    "#bring <PAD> to front and shift 0th word to <PAD> value\n",
    "first_word = ''\n",
    "for k, v in vocab.items():\n",
    "    if v == 0:\n",
    "        first_word = k\n",
    "        break\n",
    "\n",
    "pad_value = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "vocab[first_word] = pad_value\n",
    "\n",
    "#save vocab as json\n",
    "with open('vocab.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0563f8fc-ffc4-4f61-a931-cc8033936a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = {count:word for word, count in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4948b7eb-ffed-4edd-898c-e48769b6b02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vr',\n",
       " 'thatthat',\n",
       " 'timethat',\n",
       " 'itoh',\n",
       " 'itthat',\n",
       " 'loser_comma_',\n",
       " '15_comma_000',\n",
       " 'outi',\n",
       " 'youoh',\n",
       " 'dooh',\n",
       " 'nowthat',\n",
       " 'thenthat',\n",
       " 'herthat',\n",
       " 'timeoh',\n",
       " 'regiment',\n",
       " '<PAD>',\n",
       " '<EOS>',\n",
       " '<OUT>',\n",
       " '<SOS>',\n",
       " '<SEP>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.keys())[-20:] #just to make sure we have context and tokens in our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbfbe666-d2aa-4b1f-a17c-3dd58da92329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f052bba-9f1a-4317-b88f-1f634e7fb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = []\n",
    "for line in cleaned_prompt_train:\n",
    "    word_list = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            word_list.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            word_list.append(vocab[word])\n",
    "        \n",
    "    encoder_input.append(word_list)\n",
    "\n",
    "\n",
    "encoder_input_valid = []\n",
    "for line in cleaned_prompt_valid:\n",
    "    word_list = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            word_list.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            word_list.append(vocab[word])\n",
    "        \n",
    "    encoder_input_valid.append(word_list)\n",
    "\n",
    "decoder_input = []\n",
    "for line in cleaned_utterance_train:\n",
    "    word_list = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            word_list.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            word_list.append(vocab[word])        \n",
    "    decoder_input.append(word_list)\n",
    "\n",
    "decoder_input_valid = []\n",
    "for line in cleaned_utterance_valid:\n",
    "    word_list = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            word_list.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            word_list.append(vocab[word])        \n",
    "    decoder_input_valid.append(word_list)\n",
    "\n",
    "del(cleaned_prompt_train, cleaned_utterance_train, cleaned_prompt_valid, cleaned_utterance_valid, line, word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64017f95-0f3e-4b03-b318-6e5b4fce34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, MAX_LENGTH, padding='post', truncating='post')\n",
    "decoder_input = pad_sequences(decoder_input, MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "encoder_input_valid = pad_sequences(encoder_input_valid, MAX_LENGTH, padding='post', truncating='post')\n",
    "decoder_input_valid = pad_sequences(decoder_input_valid, MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "decoder_output = []\n",
    "for i in decoder_input:\n",
    "    decoder_output.append(i[1:]) \n",
    "\n",
    "decoder_output = pad_sequences(decoder_output, MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "decoder_output_valid = []\n",
    "for i in decoder_input_valid:\n",
    "    decoder_output_valid.append(i[1:]) \n",
    "\n",
    "decoder_output_valid = pad_sequences(decoder_output_valid, MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "del(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dea7e2e-7a24-4ea0-a107-e13bf1af414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76668, 23) (76668, 23) (76668, 23) 9657 9657 <PAD>\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "print(decoder_output.shape, decoder_input.shape, encoder_input.shape, len(vocab), len(inverse_vocab), inverse_vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "344ddad8-37fb-4a86-974f-e29ee73284fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe Loded!\n"
     ]
    }
   ],
   "source": [
    "#GLOVE source <-- https://nlp.stanford.edu/projects/glove/\n",
    "embedding_index = {}\n",
    "with open('../dataset/glove/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print(\"GloVe Loded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0e25971-5f55-429b-931c-6ad14e9fc9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "EMBEDDING_DIMENSION = 100\n",
    "LSTM_UNITS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a57e184-9e21-4e51-928c-86c7aaa43a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix_creater(dimension, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, dimension))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = embedding_matrix_creater(dimension=EMBEDDING_DIMENSION, word_index=vocab)\n",
    "\n",
    "del(embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b90ecaa-e13b-4a5b-a7f5-dfddb8fda51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9658, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad4a96ea-73b0-47ff-a8e0-495b50c1c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "151e6cc1-702f-4e97-9303-b0bd950fdac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 14:52:03.542579: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-17 14:52:03.542833: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(VOCAB_SIZE+1, \n",
    "                  EMBEDDING_DIMENSION, \n",
    "                  input_length=MAX_LENGTH,\n",
    "                  trainable=True)\n",
    "\n",
    "embedding_layer.build((None,))\n",
    "embedding_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38000481-59ba-453c-90aa-96598c462683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_input_layer (InputLaye  [(None, 23)]        0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " encoder_input_layer (InputLaye  [(None, 23)]        0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 23, 100)      965800      ['encoder_input_layer[0][0]',    \n",
      "                                                                  'decoder_input_layer[0][0]']    \n",
      "                                                                                                  \n",
      " encoder_bidirectional_lstm (Bi  [(None, 23, 512),   731136      ['embedding[0][0]']              \n",
      " directional)                    (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " state_h_concat (Concatenate)   (None, 512)          0           ['encoder_bidirectional_lstm[0][1\n",
      "                                                                 ]',                              \n",
      "                                                                  'encoder_bidirectional_lstm[0][3\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " state_c_concat (Concatenate)   (None, 512)          0           ['encoder_bidirectional_lstm[0][2\n",
      "                                                                 ]',                              \n",
      "                                                                  'encoder_bidirectional_lstm[0][4\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " decoder_lstm_layer (LSTM)      [(None, 23, 512),    1255424     ['embedding[1][0]',              \n",
      "                                 (None, 512),                     'state_h_concat[0][0]',         \n",
      "                                 (None, 512)]                     'state_c_concat[0][0]']         \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, 23, 512),   524800      ['encoder_bidirectional_lstm[0][0\n",
      " r)                              (None, 23, 23))                 ]',                              \n",
      "                                                                  'decoder_lstm_layer[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_concat_input_layer (Co  (None, 23, 1024)    0           ['decoder_lstm_layer[0][0]',     \n",
      " ncatenate)                                                       'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_dense_layer (Dense)    (None, 23, 9657)     9898425     ['decoder_concat_input_layer[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,375,585\n",
      "Trainable params: 13,375,585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building model\n",
    "encoder_input_layer = Input(shape=(MAX_LENGTH, ), name='encoder_input_layer')\n",
    "\n",
    "encoder_embedding_layer = embedding_layer(encoder_input_layer)\n",
    "encoder_bidirectional_lstm_layer = Bidirectional(\n",
    "    LSTM(LSTM_UNITS, return_state=True, dropout=0.05, return_sequences = True, name='encoder_lstm_layer'),\n",
    "    name='encoder_bidirectional_lstm'\n",
    ")\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_bidirectional_lstm_layer(encoder_embedding_layer)\n",
    "\n",
    "state_h = Concatenate(name='state_h_concat')([forward_h, backward_h])\n",
    "state_c = Concatenate(name='state_c_concat')([forward_c, backward_c])\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_input_layer = Input(shape=(MAX_LENGTH, ), name='decoder_input_layer')\n",
    "decoder_embedding_layer = embedding_layer(decoder_input_layer)\n",
    "decoder_lstm_layer = LSTM(LSTM_UNITS * 2, return_state=True, return_sequences=True, dropout=0.05, name='decoder_lstm_layer')\n",
    "decoder_outputs, _, _ = decoder_lstm_layer(decoder_embedding_layer, initial_state=encoder_states)\n",
    "\n",
    "# attention\n",
    "attention_layer = AttentionLayer(name='attention_layer')\n",
    "attention_output, attention_state = attention_layer([encoder_outputs, decoder_outputs])\n",
    "decoder_concat_input_layer = Concatenate(axis=-1, name='decoder_concat_input_layer')([decoder_outputs, attention_output])\n",
    "\n",
    "\n",
    "decoder_dense_layer = Dense(VOCAB_SIZE, activation='softmax', name='decoder_dense_layer')\n",
    "final_output_layer = decoder_dense_layer(decoder_concat_input_layer)\n",
    "\n",
    "model = Model([encoder_input_layer, decoder_input_layer], final_output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc191850-2ebd-44d5-b228-64364c69916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5dfb4-ceb3-444d-81b2-331dbbd11218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "history = model.fit(\n",
    "    [encoder_input, decoder_input], decoder_output,\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "    validation_data=([encoder_input_valid, decoder_input_valid], decoder_output_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d698c674-76ce-4121-887a-b3e496584815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "model.save('chatbot.h5')\n",
    "model.save_weights('chatbot_weights.h5')\n",
    "\n",
    "#save history for later analysis\n",
    "history_dict = history.history\n",
    "\n",
    "# convert NumPy arrays to lists for JSON compatibility\n",
    "for key in history_dict.keys():\n",
    "    history_dict[key] = [float(i) for i in history_dict[key]]\n",
    "\n",
    "# save the history dictionary to a JSON file\n",
    "with open('chatbot_history.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e29a2-ff08-4928-8c94-b5d434dcda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['sparse_categorical_accuracy'], label='accuracy')\n",
    "#plt.plot(history.history['val_sparse_categorical_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb5dfcef-2451-47b2-84c7-25aa88fdb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model inference for generating responses\n",
    "inference_encoder_model = Model(encoder_input_layer, [encoder_outputs, encoder_states])\n",
    "\n",
    "inference_decoder_state_input_h = Input(shape=( LSTM_UNITS * 2,))\n",
    "inference_decoder_state_input_c = Input(shape=( LSTM_UNITS * 2,))\n",
    "\n",
    "inference_decoder_states_inputs = [inference_decoder_state_input_h, inference_decoder_state_input_c]\n",
    "\n",
    "\n",
    "inference_decoder_outputs, inference_state_h, inference_state_c = decoder_lstm_layer(decoder_embedding_layer , initial_state=inference_decoder_states_inputs)\n",
    "\n",
    "\n",
    "inference_decoder_states = [inference_state_h, inference_state_c]\n",
    "\n",
    "#decoder_output = dec_dense(decoder_outputs)\n",
    "\n",
    "inference_decoder_model = Model(\n",
    "    [decoder_input_layer, inference_decoder_states_inputs],\n",
    "    [inference_decoder_outputs] + inference_decoder_states\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e264a29e-073e-4af5-ace9-0d099b9d184b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "separator = '-'\n",
    "input_text = \"\"\n",
    "while input_text != 'exit':\n",
    "    input_text = input(\"YOU : \")\n",
    "    if(input_text == 'exit'):\n",
    "        print(\"Bye! Talk to you later.\")\n",
    "    else:\n",
    "        try:\n",
    "            if separator in input_text:\n",
    "                prompt, context = input_text.split(separator, 1)  # split only on the first occurrence\n",
    "            else:\n",
    "                prompt = input_text\n",
    "                context = \"joyful\"\n",
    "                \n",
    "            input_cleaned = expand_contractions_and_clean(prompt.strip()) + ' <SEP> ' + context.strip()\n",
    "            input_cleaned = [input_cleaned]\n",
    "            \n",
    "            text = []\n",
    "            for x in input_cleaned:\n",
    "                lst = []\n",
    "                for y in x.split():\n",
    "                    try:\n",
    "                        lst.append(vocab[y])\n",
    "                    except:\n",
    "                        lst.append(vocab['<OUT>'])\n",
    "                text.append(lst)\n",
    "            text = pad_sequences(text, MAX_LENGTH, padding='post')\n",
    "    \n",
    "            inference_encoder_output, inference_encoder_states = inference_encoder_model.predict( text )\n",
    "    \n",
    "            empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "            empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "            stop_condition = False\n",
    "            decoded_translation = ''\n",
    "    \n",
    "            while not stop_condition :\n",
    "                inference_decoder_outputs , h , c = inference_decoder_model.predict([ empty_target_seq ] + inference_encoder_states )\n",
    "                \n",
    "                ###\n",
    "                ###########################\n",
    "                inference_attention_output, inference_attention_states = attention_layer([inference_encoder_output, inference_decoder_outputs])\n",
    "                inference_decoder_concat_input = Concatenate(axis=-1)([inference_decoder_outputs, inference_attention_output])\n",
    "                inference_decoder_concat_input = decoder_dense_layer(inference_decoder_concat_input)\n",
    "                ###########################\n",
    "    \n",
    "                sampled_word_index = np.argmax( inference_decoder_concat_input[0, -1, :] )\n",
    "                sampled_word = inverse_vocab[sampled_word_index] + ' '\n",
    "    \n",
    "                if sampled_word != '<EOS> ':\n",
    "                    decoded_translation += sampled_word           \n",
    "    \n",
    "                if sampled_word == '<EOS> ' or len(decoded_translation.split()) > MAX_LENGTH:\n",
    "                    stop_condition = True\n",
    "    \n",
    "                empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "                empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "                inference_encoder_states = [ h , c ] \n",
    "    \n",
    "            print(\"CHATBOT : \", decoded_translation )\n",
    "    \n",
    "        except Exception as e:\n",
    "            #print(\"I couldn't get you. Please try again.\")\n",
    "            print(e)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
